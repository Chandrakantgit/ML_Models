{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for the model\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_note_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/training_set_label.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VWTI</th>\n",
       "      <th>SWTI</th>\n",
       "      <th>CWTI</th>\n",
       "      <th>EI</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.2634</td>\n",
       "      <td>-4.4862</td>\n",
       "      <td>3.6558</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2718</td>\n",
       "      <td>1.7837</td>\n",
       "      <td>2.1161</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.9411</td>\n",
       "      <td>-12.8792</td>\n",
       "      <td>13.0597</td>\n",
       "      <td>-3.312500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5195</td>\n",
       "      <td>-3.2633</td>\n",
       "      <td>3.0895</td>\n",
       "      <td>-0.984900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5698</td>\n",
       "      <td>-4.4076</td>\n",
       "      <td>5.9856</td>\n",
       "      <td>0.078002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     VWTI     SWTI     CWTI        EI  Class\n",
       "0  2.2634  -4.4862   3.6558 -0.612510      0\n",
       "1  3.2718   1.7837   2.1161  0.613340      0\n",
       "2 -3.9411 -12.8792  13.0597 -3.312500      1\n",
       "3  0.5195  -3.2633   3.0895 -0.984900      0\n",
       "4  2.5698  -4.4076   5.9856  0.078002      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_note_data.head()\n",
    "#getting a short insoght of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing test data\n",
    "test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/testing_set_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VWTI</th>\n",
       "      <th>SWTI</th>\n",
       "      <th>CWTI</th>\n",
       "      <th>EI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.40804</td>\n",
       "      <td>0.54214</td>\n",
       "      <td>-0.52725</td>\n",
       "      <td>0.65860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.71810</td>\n",
       "      <td>-8.50890</td>\n",
       "      <td>12.36300</td>\n",
       "      <td>-0.95518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.50400</td>\n",
       "      <td>10.36710</td>\n",
       "      <td>-4.41300</td>\n",
       "      <td>-4.02110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.68490</td>\n",
       "      <td>8.74890</td>\n",
       "      <td>-1.26410</td>\n",
       "      <td>-1.38580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.74320</td>\n",
       "      <td>2.10860</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>1.65430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VWTI      SWTI      CWTI       EI\n",
       "0 -0.40804   0.54214  -0.52725  0.65860\n",
       "1 -3.71810  -8.50890  12.36300 -0.95518\n",
       "2  5.50400  10.36710  -4.41300 -4.02110\n",
       "3  1.68490   8.74890  -1.26410 -1.38580\n",
       "4  4.74320   2.10860   0.13680  1.65430"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()\n",
    "#getting an insight of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_note_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1096 entries, 0 to 1095\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   VWTI    1096 non-null   float64\n",
      " 1   SWTI    1096 non-null   float64\n",
      " 2   CWTI    1096 non-null   float64\n",
      " 3   EI      1096 non-null   float64\n",
      " 4   Class   1096 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 42.9 KB\n"
     ]
    }
   ],
   "source": [
    "bank_note_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bank_note_data.drop(\"Class\",axis=1)#components on which model is trained\n",
    "y=bank_note_data['Class']#target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STep 1 building a model , for which we willl import some libraries and functions\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building layers and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chandrakant\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(10,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chandrakant\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Compiling the Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer=RMSprop(0.01)#learning rate of model is set as 0.01\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#printing the summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 176 samples\n",
      "Epoch 1/200\n",
      "700/700 [==============================] - 1s 810us/sample - loss: 0.5077 - acc: 0.7843 - val_loss: 0.2241 - val_acc: 0.9773\n",
      "Epoch 2/200\n",
      "700/700 [==============================] - 0s 68us/sample - loss: 0.1463 - acc: 0.9871 - val_loss: 0.0759 - val_acc: 0.9943\n",
      "Epoch 3/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0638 - acc: 0.9914 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 4/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 5/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 6/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 7/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 9/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 7.5592e-04 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 5.0580e-04 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 5.0637e-04 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.8353e-04 - acc: 1.0000 - val_loss: 2.4004e-04 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.5702e-04 - acc: 1.0000 - val_loss: 3.8102e-04 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.2715e-04 - acc: 1.0000 - val_loss: 1.4577e-04 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.2551e-04 - acc: 1.0000 - val_loss: 1.7156e-04 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.4079e-04 - acc: 1.0000 - val_loss: 8.4168e-05 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.8953e-04 - acc: 1.0000 - val_loss: 6.8448e-05 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.5286e-04 - acc: 1.0000 - val_loss: 7.6330e-05 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3775e-04 - acc: 1.0000 - val_loss: 3.0919e-05 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.1169e-05 - acc: 1.0000 - val_loss: 4.0953e-05 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.5989e-05 - acc: 1.0000 - val_loss: 1.6997e-05 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 3.9634e-05 - acc: 1.0000 - val_loss: 9.8003e-06 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.5829e-05 - acc: 1.0000 - val_loss: 8.0829e-06 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.0646e-05 - acc: 1.0000 - val_loss: 5.0749e-06 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.2992e-05 - acc: 1.0000 - val_loss: 1.1516e-05 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.6123e-05 - acc: 1.0000 - val_loss: 3.6278e-06 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.5092e-05 - acc: 1.0000 - val_loss: 3.2625e-06 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.8673e-06 - acc: 1.0000 - val_loss: 1.5700e-06 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.3694e-05 - acc: 1.0000 - val_loss: 1.4944e-06 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.9672e-06 - acc: 1.0000 - val_loss: 1.1610e-06 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.4463e-06 - acc: 1.0000 - val_loss: 6.1814e-07 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.2792e-06 - acc: 1.0000 - val_loss: 5.8549e-07 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.3230e-06 - acc: 1.0000 - val_loss: 1.1056e-06 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 5.4225e-06 - acc: 1.0000 - val_loss: 1.6266e-06 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.7571e-06 - acc: 1.0000 - val_loss: 2.9670e-07 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3727e-06 - acc: 1.0000 - val_loss: 2.2678e-07 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.5978e-06 - acc: 1.0000 - val_loss: 1.7416e-07 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.6781e-07 - acc: 1.0000 - val_loss: 1.4022e-07 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.8145e-06 - acc: 1.0000 - val_loss: 3.0027e-07 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.2166e-06 - acc: 1.0000 - val_loss: 1.4956e-07 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.7913e-07 - acc: 1.0000 - val_loss: 8.8696e-08 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.9041e-07 - acc: 1.0000 - val_loss: 6.5127e-08 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.0341e-07 - acc: 1.0000 - val_loss: 1.1988e-07 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.4750e-07 - acc: 1.0000 - val_loss: 4.2085e-08 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.8106e-07 - acc: 1.0000 - val_loss: 2.7500e-08 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.2782e-07 - acc: 1.0000 - val_loss: 2.3460e-08 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 3.0170e-07 - acc: 1.0000 - val_loss: 3.0536e-08 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.3958e-07 - acc: 1.0000 - val_loss: 1.6759e-08 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.5691e-08 - acc: 1.0000 - val_loss: 7.3694e-09 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.8012e-08 - acc: 1.0000 - val_loss: 2.4967e-08 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.4618e-08 - acc: 1.0000 - val_loss: 4.1728e-09 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.8905e-07 - acc: 1.0000 - val_loss: 2.1792e-08 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.1618e-08 - acc: 1.0000 - val_loss: 7.6850e-09 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.5423e-08 - acc: 1.0000 - val_loss: 3.6693e-09 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.4450e-08 - acc: 1.0000 - val_loss: 3.1525e-09 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.0297e-08 - acc: 1.0000 - val_loss: 1.0045e-08 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.0453e-08 - acc: 1.0000 - val_loss: 1.9647e-09 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "700/700 [==============================] - ETA: 0s - loss: 8.9190e-11 - acc: 1.000 - 0s 38us/sample - loss: 1.8522e-08 - acc: 1.0000 - val_loss: 1.9700e-09 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3839e-08 - acc: 1.0000 - val_loss: 2.0662e-09 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.0801e-08 - acc: 1.0000 - val_loss: 1.2302e-09 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.5058e-09 - acc: 1.0000 - val_loss: 1.2277e-09 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.3277e-09 - acc: 1.0000 - val_loss: 9.6846e-10 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.2447e-09 - acc: 1.0000 - val_loss: 2.2124e-09 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.5000e-09 - acc: 1.0000 - val_loss: 1.2161e-09 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.7137e-09 - acc: 1.0000 - val_loss: 2.3308e-09 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.6147e-09 - acc: 1.0000 - val_loss: 6.2711e-10 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 4.8012e-09 - acc: 1.0000 - val_loss: 6.0703e-10 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.5239e-09 - acc: 1.0000 - val_loss: 2.7664e-09 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.6698e-09 - acc: 1.0000 - val_loss: 6.7227e-10 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.8034e-09 - acc: 1.0000 - val_loss: 8.0734e-10 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 3.8748e-09 - acc: 1.0000 - val_loss: 9.5831e-10 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 3.4380e-09 - acc: 1.0000 - val_loss: 5.5781e-10 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.9403e-09 - acc: 1.0000 - val_loss: 3.9796e-10 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 3.1146e-09 - acc: 1.0000 - val_loss: 4.5904e-10 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.8562e-09 - acc: 1.0000 - val_loss: 3.9989e-10 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.6814e-09 - acc: 1.0000 - val_loss: 6.8398e-10 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.6520e-09 - acc: 1.0000 - val_loss: 4.1177e-10 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.8860e-09 - acc: 1.0000 - val_loss: 6.5838e-10 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.4023e-09 - acc: 1.0000 - val_loss: 3.2694e-10 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.0713e-09 - acc: 1.0000 - val_loss: 4.1309e-10 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.5749e-09 - acc: 1.0000 - val_loss: 3.6321e-10 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.8805e-09 - acc: 1.0000 - val_loss: 4.4958e-10 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 2.1761e-09 - acc: 1.0000 - val_loss: 3.7579e-10 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.8348e-09 - acc: 1.0000 - val_loss: 3.1744e-10 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.9688e-09 - acc: 1.0000 - val_loss: 2.6252e-10 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.7311e-09 - acc: 1.0000 - val_loss: 2.9760e-10 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.7388e-09 - acc: 1.0000 - val_loss: 5.0007e-10 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.6860e-09 - acc: 1.0000 - val_loss: 3.0951e-10 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.5293e-09 - acc: 1.0000 - val_loss: 2.9355e-10 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 2.0755e-09 - acc: 1.0000 - val_loss: 7.8983e-10 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.9967e-09 - acc: 1.0000 - val_loss: 3.8297e-10 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 1.5392e-09 - acc: 1.0000 - val_loss: 2.5683e-10 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.4066e-09 - acc: 1.0000 - val_loss: 2.1622e-10 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3499e-09 - acc: 1.0000 - val_loss: 2.3888e-10 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.5333e-09 - acc: 1.0000 - val_loss: 2.7706e-10 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3334e-09 - acc: 1.0000 - val_loss: 2.8969e-10 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3897e-09 - acc: 1.0000 - val_loss: 2.1577e-10 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.3620e-09 - acc: 1.0000 - val_loss: 3.8414e-10 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.4296e-09 - acc: 1.0000 - val_loss: 1.7800e-10 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.1766e-09 - acc: 1.0000 - val_loss: 2.0357e-10 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.3683e-09 - acc: 1.0000 - val_loss: 3.5896e-10 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.3085e-09 - acc: 1.0000 - val_loss: 2.0850e-10 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.1021e-09 - acc: 1.0000 - val_loss: 2.0874e-10 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.0960e-09 - acc: 1.0000 - val_loss: 2.9035e-10 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.1897e-09 - acc: 1.0000 - val_loss: 2.6712e-10 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.1988e-09 - acc: 1.0000 - val_loss: 1.8001e-10 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.1235e-09 - acc: 1.0000 - val_loss: 1.9168e-10 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.2673e-09 - acc: 1.0000 - val_loss: 2.4335e-10 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.0410e-09 - acc: 1.0000 - val_loss: 2.3310e-10 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.0474e-09 - acc: 1.0000 - val_loss: 2.3468e-10 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.0105e-09 - acc: 1.0000 - val_loss: 1.6387e-10 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 1.1849e-09 - acc: 1.0000 - val_loss: 2.0110e-10 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 9.1900e-10 - acc: 1.0000 - val_loss: 2.1855e-10 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 9.6073e-10 - acc: 1.0000 - val_loss: 1.5499e-10 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 9.2782e-10 - acc: 1.0000 - val_loss: 1.6973e-10 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 1.0901e-09 - acc: 1.0000 - val_loss: 2.1045e-10 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.8065e-10 - acc: 1.0000 - val_loss: 2.1526e-10 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 9.2733e-10 - acc: 1.0000 - val_loss: 2.2797e-10 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.5423e-10 - acc: 1.0000 - val_loss: 1.7165e-10 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.4498e-10 - acc: 1.0000 - val_loss: 2.9910e-10 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.2198e-10 - acc: 1.0000 - val_loss: 1.7521e-10 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.3094e-10 - acc: 1.0000 - val_loss: 2.2511e-10 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.4313e-10 - acc: 1.0000 - val_loss: 1.4736e-10 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.5200e-10 - acc: 1.0000 - val_loss: 2.7048e-10 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 9.1266e-10 - acc: 1.0000 - val_loss: 1.9310e-10 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.4554e-10 - acc: 1.0000 - val_loss: 1.8418e-10 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.5668e-10 - acc: 1.0000 - val_loss: 1.7263e-10 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 8.5557e-10 - acc: 1.0000 - val_loss: 1.1857e-10 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 9.2055e-10 - acc: 1.0000 - val_loss: 1.5072e-10 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.3429e-10 - acc: 1.0000 - val_loss: 1.4309e-10 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.4064e-10 - acc: 1.0000 - val_loss: 1.8643e-10 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.0849e-10 - acc: 1.0000 - val_loss: 1.8128e-10 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.0124e-10 - acc: 1.0000 - val_loss: 3.2245e-10 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.8904e-10 - acc: 1.0000 - val_loss: 1.7889e-10 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.0321e-10 - acc: 1.0000 - val_loss: 1.7376e-10 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.1676e-10 - acc: 1.0000 - val_loss: 1.7212e-10 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.9385e-10 - acc: 1.0000 - val_loss: 1.0603e-10 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 8.2892e-10 - acc: 1.0000 - val_loss: 1.8154e-10 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.3026e-10 - acc: 1.0000 - val_loss: 1.6670e-10 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.2468e-10 - acc: 1.0000 - val_loss: 1.4965e-10 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.3597e-10 - acc: 1.0000 - val_loss: 1.5270e-10 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.8807e-10 - acc: 1.0000 - val_loss: 9.6499e-11 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.2886e-10 - acc: 1.0000 - val_loss: 1.9524e-10 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.9232e-10 - acc: 1.0000 - val_loss: 1.7553e-10 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.1186e-10 - acc: 1.0000 - val_loss: 1.2382e-10 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.3723e-10 - acc: 1.0000 - val_loss: 1.2513e-10 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.7177e-10 - acc: 1.0000 - val_loss: 1.4144e-10 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.0787e-10 - acc: 1.0000 - val_loss: 1.5027e-10 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.8188e-10 - acc: 1.0000 - val_loss: 1.6524e-10 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.0214e-10 - acc: 1.0000 - val_loss: 1.5095e-10 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.7311e-10 - acc: 1.0000 - val_loss: 1.5903e-10 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 7.3442e-10 - acc: 1.0000 - val_loss: 1.5377e-10 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.3073e-10 - acc: 1.0000 - val_loss: 1.5684e-10 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.5525e-10 - acc: 1.0000 - val_loss: 1.6303e-10 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 7.6813e-10 - acc: 1.0000 - val_loss: 9.3609e-11 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.9929e-10 - acc: 1.0000 - val_loss: 1.2954e-10 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.9350e-10 - acc: 1.0000 - val_loss: 1.2386e-10 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.8270e-10 - acc: 1.0000 - val_loss: 1.2094e-10 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.9309e-10 - acc: 1.0000 - val_loss: 1.2318e-10 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.1344e-10 - acc: 1.0000 - val_loss: 1.2712e-10 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.4498e-10 - acc: 1.0000 - val_loss: 1.3305e-10 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.9377e-10 - acc: 1.0000 - val_loss: 1.4031e-10 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.9917e-10 - acc: 1.0000 - val_loss: 1.8441e-10 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.3152e-10 - acc: 1.0000 - val_loss: 1.5671e-10 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 6.0912e-10 - acc: 1.0000 - val_loss: 1.5569e-10 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 6.0188e-10 - acc: 1.0000 - val_loss: 9.4178e-11 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.4203e-10 - acc: 1.0000 - val_loss: 9.9678e-11 - val_acc: 1.0000\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 46us/sample - loss: 5.7264e-10 - acc: 1.0000 - val_loss: 1.0662e-10 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 5.9919e-10 - acc: 1.0000 - val_loss: 1.1330e-10 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.2713e-10 - acc: 1.0000 - val_loss: 2.1020e-10 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "700/700 [==============================] - 0s 57us/sample - loss: 5.9782e-10 - acc: 1.0000 - val_loss: 1.3447e-10 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.4756e-10 - acc: 1.0000 - val_loss: 1.3594e-10 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.4685e-10 - acc: 1.0000 - val_loss: 1.4039e-10 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.8162e-10 - acc: 1.0000 - val_loss: 1.4724e-10 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.8086e-10 - acc: 1.0000 - val_loss: 8.3346e-11 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.2929e-10 - acc: 1.0000 - val_loss: 8.9529e-11 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.5747e-10 - acc: 1.0000 - val_loss: 9.4414e-11 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.9788e-10 - acc: 1.0000 - val_loss: 1.0343e-10 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.3980e-10 - acc: 1.0000 - val_loss: 1.8467e-10 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.8515e-10 - acc: 1.0000 - val_loss: 1.0286e-10 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.8998e-10 - acc: 1.0000 - val_loss: 1.0662e-10 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.0203e-10 - acc: 1.0000 - val_loss: 1.1215e-10 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.1901e-10 - acc: 1.0000 - val_loss: 1.1871e-10 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.4221e-10 - acc: 1.0000 - val_loss: 1.2737e-10 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.5047e-10 - acc: 1.0000 - val_loss: 7.4740e-11 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.2688e-10 - acc: 1.0000 - val_loss: 1.2593e-10 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.1536e-10 - acc: 1.0000 - val_loss: 1.2893e-10 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.2766e-10 - acc: 1.0000 - val_loss: 1.2930e-10 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.5583e-10 - acc: 1.0000 - val_loss: 1.3105e-10 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.8926e-10 - acc: 1.0000 - val_loss: 1.3342e-10 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.9148e-10 - acc: 1.0000 - val_loss: 1.3996e-10 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.9470e-10 - acc: 1.0000 - val_loss: 7.8499e-11 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.1900e-10 - acc: 1.0000 - val_loss: 8.3015e-11 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "700/700 [==============================] - 0s 34us/sample - loss: 5.6002e-10 - acc: 1.0000 - val_loss: 9.0601e-11 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 5.6188e-10 - acc: 1.0000 - val_loss: 9.7674e-11 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 6.0446e-10 - acc: 1.0000 - val_loss: 9.1603e-11 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 7.1372e-10 - acc: 1.0000 - val_loss: 1.0967e-10 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "700/700 [==============================] - 0s 46us/sample - loss: 4.6587e-10 - acc: 1.0000 - val_loss: 1.0097e-10 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,validation_split=0.2,epochs=200,batch_size=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 95us/sample - loss: 1.6698e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6698021878635937e-07, 1.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5822392e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5822392e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [3.5762787e-05],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 9.9999988e-01, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 2.8014183e-06, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 2.8014183e-06, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 2.8014183e-06, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 2.8014183e-06, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=answer.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ans:\n",
    "    lis.append(int(x))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
